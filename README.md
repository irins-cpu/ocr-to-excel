OCR-to-Excel Tool
This project automates the extraction of printed and handwritten text from scanned paper sheets and saves the recognized data into a structured Excel file.

It was developed and tested during an internship as a prototype OCR pipeline.

ğŸ“Œ What It Does
Processes scanned warehouse forms in .jpg / .png format.

Extracts tabular data from the roll list pages, including:

Roll number (e.g., B12947)

Format (mm)

Weight (kg)

Grammage (g/mÂ²)

Comment (if handwritten)

Saves the structured data into output/results.xlsx.
Produces debug images and logs in /output/.

âš ï¸ Title pages (the first page of each delivery sheet) are intentionally not processed â€” the program only reads the tables with roll data.

ğŸ›  Technologies Used
Python 3.11
EasyOCR â€” multilingual text detection
OpenCV â€” image preprocessing and table segmentation
Pandas + OpenPyXL â€” Excel export
Pillow â€” image handling
Tesseract OCR â€” for mixed Cyrillic/Latin text

âš™ï¸ Installation

Install Tesseract OCR
Download: Tesseract at UB Mannheim
Install to the default path: C:\Program Files\Tesseract-OCR
During installation, include English and Russian language packs.
Add to PATH: C:\Program Files\Tesseract-OCR
Verify installation:
tesseract --version

Clone Repository & Create Virtual Environment
git clone <your-repo-url>
cd ocr_to_excel
python -m venv venv
venv\Scripts\activate # on Windows

Install Dependencies
pip install -r requirements.txt

Run the Tool
python test_table.py

The processed Excel file will appear in the output/ folder as results.xlsx.

ğŸ“ Project Structure
ocr_to_excel/
â”œâ”€â”€ input/ # Folder for input images (JPG/PNG)
â”œâ”€â”€ output/ # Debug images + Excel results
â”œâ”€â”€ venv/ # Virtual environment
â”œâ”€â”€ ocr_engine.py # Core OCR logic
â”œâ”€â”€ test_table.py # Main script for testing OCR
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ README.md # Documentation
â””â”€â”€ .gitignore

ğŸ§ª Experimental Results (Handwritten + Printed Tables)
Field | Accuracy | Notes
Roll Number | ~30% | Some numbers correctly detected (e.g., B12952), others missed or misread
Format (mm) | ~45% | Detects printed numbers, but columns sometimes shift
Weight (kg) | ~25% | Often confused with grammage
Grammage (g/mÂ²) | ~20% | Rarely recognized correctly
Comment (handwritten) | <15% | OCR fails on cursive handwriting
Overall Accuracy: â‰ˆ 27%

ğŸ“‰ Limitations & Observations
Handwritten Cyrillic text is rarely recognized â€” both EasyOCR and Tesseract fail on cursive styles.
Table segmentation with OpenCV works on clean scans but struggles when grid lines are faint or broken.
Mixed Cyrillic and Latin text (e.g., B vs Ğ’) often leads to character confusion.
Windows.Media.Ocr (via winsdk) gave higher accuracy but is unreliable across systems and versions.

ğŸ’¡ Future Improvements
Use a hybrid approach:

Detect table layout via machine learning (e.g., Detectron or YOLO layout models)

Combine OCR from Google Vision or ABBYY Cloud for higher accuracy

Build a simple Tkinter GUI for file selection and batch processing

Add a post-processing correction module using regex validation and fuzzy matching for roll numbers

ğŸ“‹ Status
ğŸš§ Prototype Stage (Internship Project)
Recognizes around 25â€“30% of text fields correctly on real scanned forms.
Suitable for further research and integration testing â€” not for production use yet.