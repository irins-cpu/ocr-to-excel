# ğŸ“„ OCR-to-Excel Tool

This project automates the extraction of printed and handwritten text from scanned paper sheets and saves the recognized data into a structured Excel file.Â Â 

It was developed and tested during an internship as a prototype OCR pipeline.

---

## ğŸ“Œ What It Does

- Processes scanned **warehouse forms** in `.jpg` / `.png` format.Â Â 

- Extracts tabular data from the **roll list pages**, including:Â Â 

Â  - Roll number (e.g., `B12947`)Â Â 

Â  - Format (mm)Â Â 

Â  - Weight (kg)Â Â 

Â  - Grammage (g/mÂ²)Â Â 

Â  - Comment (if handwritten)Â Â 

- Saves the structured data into `output/results.xlsx`.Â Â 

- Produces debug images and logs in `/output/`.

> âš ï¸ Title pages (the first page of each delivery sheet) are intentionally **not processed** --- the program only reads the tables with roll data.

---

## ğŸ›  Technologies Used

- **Python 3.11**

- **EasyOCR** --- multilingual text detectionÂ Â 

- **OpenCV** --- image preprocessing and table segmentationÂ Â 

- **Pandas + OpenPyXL** --- Excel exportÂ Â 

- **Pillow** --- image handlingÂ Â 

- **Tesseract OCR** --- for mixed Cyrillic/Latin text

---

## âš™ï¸ Installation

### 1. Install Tesseract OCR

- Download: [Tesseract at UB Mannheim](https://github.com/UB-Mannheim/tesseract/wiki)Â Â 

- Install to the default path:Â Â 

Â  `C:\Program Files\Tesseract-OCR`

- During installation, include **English** and **Russian** language packs.Â Â 

- Add to PATH:

`C:\Program Files\Tesseract-OCR`



Verify installation:

`
tesseract --version
`
### 2\. Clone Repository & Create Virtual Environment




Copy code:

```bash
git clone <your-repo-url>

cd ocr_to_excel

python -m venv venv

venv\Scripts\activateÂ  Â # on Windows
```
### 3\. Install Dependencies



Copy code:
```bash
pip install -r requirements.txt
```
### 4\. Run the Tool


Copy code:
```bash
python test_table.py
```
The processed Excel file will appear in the output/ folder as `results.xlsx`.

---
## ğŸ“ Project Structure

```graphql
ocr_to_excel/
â”œâ”€â”€ input/Â  Â  Â  Â  Â  Â  Â  # Folder for input images (JPG/PNG)
â”œâ”€â”€ output/Â  Â  Â  Â  Â  Â  Â # Debug images + Excel results
â”œâ”€â”€ venv/Â  Â  Â  Â  Â  Â  Â  Â # Virtual environment
â”œâ”€â”€ ocr_engine.pyÂ  Â  Â  Â # Core OCR logic
â”œâ”€â”€ test_table.pyÂ  Â  Â  Â # Main script for testing OCR
â”œâ”€â”€ requirements.txtÂ  Â  # Dependencies
â”œâ”€â”€ README.mdÂ  Â  Â  Â  Â  Â # Documentation
â””â”€â”€ .gitignore
```

## ğŸ§ª Experimental Results (Handwritten + Printed Tables)

| Field | Accuracy | Notes |
|--------|-----------|-------|
| Roll Number | ~30% | Some numbers correctly detected (e.g., B12952), others missed or misread |
| Format (mm) | ~45% | Detects printed numbers, but columns sometimes shift |
| Weight (kg) | ~25% | Often confused with grammage |
| Grammage (g/mÂ²) | ~20% | Rarely recognized correctly |
| Comment (handwritten) | <15% | OCR fails on cursive handwriting |
| **Overall Accuracy** | **â‰ˆ 27%** | â€” |

## ğŸ“‰ Limitations & Observations

- Handwritten Cyrillic text is rarely recognized --- both EasyOCR and Tesseract fail on cursive styles.

- Table segmentation with OpenCV works on clean scans but struggles when grid lines are faint or broken.

- Mixed Cyrillic and Latin text (e.g., B vs Ğ’) often leads to character confusion.

- Windows.Media.Ocr (via winsdk) gave higher accuracy but is unreliable across systems and versions.

## ğŸ’¡ Future Improvements

Hybrid approach:

- Detect table layout via machine learning (e.g., Detectron or YOLO layout models)

- Combine OCR from Google Vision or ABBYY Cloud for higher accuracy.

- Build a simple Tkinter GUI for file selection and batch processing.

- Add a post-processing correction module using regex validation and fuzzy matching for roll numbers.

## ğŸ“‹ Status

ğŸš§ Prototype Stage (Internship Project)

**Recognizes around 25--30% of text fields correctly on real scanned forms.**

Suitable for further research and integration testing --- not for production use yet.